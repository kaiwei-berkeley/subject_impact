{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZKW\\Anaconda3\\envs\\data-x\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"..\\\\data\\\\oag2019\\\\aminer_year\\\\\"\n",
    "file_names = os.listdir(data_dir)\n",
    "years = np.arange(2004,2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### reads a txt file and get keywords, connected by '_'\n",
    "def get_keywords(data_dir,file):\n",
    "    f = open(data_dir+file,'r',encoding = 'utf8')\n",
    "    kws = [json.loads(line)['keywords'] for line in f]\n",
    "    connect_kws = [[re.sub('\\s+','_',i) for i in words] for words in key]\n",
    "    return connect_kws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### obtain w2v model and save wv file to dir\n",
    "def get_model_save(context,save_dir_name, size = 100, window = 10):\n",
    "    model = Word2Vec(\n",
    "            context,\n",
    "            size=size,\n",
    "            window=window,\n",
    "            min_count=2,\n",
    "            workers=10)\n",
    "    wv = model.wv\n",
    "    wv.save_word2vec_format(save_dir_name, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017\n",
      " 2018]\n",
      "reading keywords: aminer_2004.txt\n",
      "training word vector: wv_2004.txt\n",
      "reading keywords: aminer_2005.txt\n",
      "training word vector: wv_2005.txt\n",
      "reading keywords: aminer_2006.txt\n",
      "training word vector: wv_2006.txt\n",
      "reading keywords: aminer_2007.txt\n",
      "training word vector: wv_2007.txt\n",
      "reading keywords: aminer_2008.txt\n",
      "training word vector: wv_2008.txt\n",
      "reading keywords: aminer_2009.txt\n",
      "training word vector: wv_2009.txt\n",
      "reading keywords: aminer_2010.txt\n",
      "training word vector: wv_2010.txt\n",
      "reading keywords: aminer_2011.txt\n",
      "training word vector: wv_2011.txt\n",
      "reading keywords: aminer_2012.txt\n",
      "training word vector: wv_2012.txt\n",
      "reading keywords: aminer_2013.txt\n",
      "training word vector: wv_2013.txt\n",
      "reading keywords: aminer_2014.txt\n",
      "training word vector: wv_2014.txt\n",
      "reading keywords: aminer_2015.txt\n",
      "training word vector: wv_2015.txt\n",
      "reading keywords: aminer_2016.txt\n",
      "training word vector: wv_2016.txt\n",
      "reading keywords: aminer_2017.txt\n",
      "training word vector: wv_2017.txt\n",
      "reading keywords: aminer_2018.txt\n",
      "training word vector: wv_2018.txt\n"
     ]
    }
   ],
   "source": [
    "### get keywords word-embedding vectors for all year\n",
    "print(years)\n",
    "out_dir = \"..\\\\data\\\\oag2019\\\\aminer_year\\\\wv_year\"\n",
    "for i in range(len(years)):\n",
    "    out_name = \"wv_\"+str(years[i])+\".txt\"\n",
    "    file = file_names[i]\n",
    "    print(\"reading keywords: \"+file)\n",
    "    context = get_keywords(data_dir,file)\n",
    "    print(\"training word vector: \"+out_name)\n",
    "    get_model_save(context,out_dir+\"\\\\\"+out_name,size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wv(wv_dir):\n",
    "    wv_list = []\n",
    "    wv_files = os.listdir(wv_dir)\n",
    "    for wv in wv_files:\n",
    "        print(\"loading: \"+wv)\n",
    "        wv_list.append(KeyedVectors.load_word2vec_format(wv_dir+'\\\\'+wv, binary=False))\n",
    "    return wv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading: wv_2004.txt\n",
      "loading: wv_2005.txt\n",
      "loading: wv_2006.txt\n",
      "loading: wv_2007.txt\n",
      "loading: wv_2008.txt\n",
      "loading: wv_2009.txt\n",
      "loading: wv_2010.txt\n",
      "loading: wv_2011.txt\n",
      "loading: wv_2012.txt\n",
      "loading: wv_2013.txt\n",
      "loading: wv_2014.txt\n",
      "loading: wv_2015.txt\n",
      "loading: wv_2016.txt\n",
      "loading: wv_2017.txt\n",
      "loading: wv_2018.txt\n"
     ]
    }
   ],
   "source": [
    "wv_dir = \"..\\\\data\\\\oag2019\\\\aminer_year\\\\wv_year\"\n",
    "wv_list = load_wv(wv_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(wv_list,w1,w2,start = 0):\n",
    "    sim = []\n",
    "    for i in range(len(wv_list)):\n",
    "        if i >= start:\n",
    "            sim.append(wv_list[i].similarity(w1,w2))\n",
    "    plt.plot(years, sim, linestyle='solid',label = w1+\"/\"+w2)\n",
    "    plt.title(\"cosine distance\")\n",
    "    plt.ylim(-1,1)\n",
    "    plt.legend()\n",
    "    return sim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'years' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e1008e590770>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mw3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"jazz\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-451f143247ec>\u001b[0m in \u001b[0;36mget_similarity\u001b[1;34m(wv_list, w1, w2, start)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0msim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwv_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myears\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'solid'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cosine distance\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'years' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## try 3 keywords\n",
    "w1 = \"linear_model\"\n",
    "w2 = \"machine_learning\"\n",
    "w3 = \"jazz\"\n",
    "plt.figure(figsize=(10,6))\n",
    "v = get_similarity(wv_list,w1,w2)\n",
    "v = get_similarity(wv_list,w1,w3)\n",
    "v = get_similarity(wv_list,w2,w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
