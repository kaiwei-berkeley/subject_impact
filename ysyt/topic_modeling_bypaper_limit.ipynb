{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create dataframe that matches paper abstract with subjects **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_id = []\n",
    "abstract = []\n",
    "\n",
    "f = open('aminer_2015.txt','r',encoding = 'utf8')\n",
    "f.readline()\n",
    "for i, line in enumerate(f):\n",
    "        if (i+2) % 250000 == 0:\n",
    "            print('file '+file+': ',round((i+2)/1000000*100,1),\"%\")\n",
    "        json_line = json.loads(line)\n",
    "        if 'year' in json_line and 'keywords' in json_line and \\\n",
    "        'abstract' in json_line and 'lang' in json_line and \\\n",
    "        'references' in json_line and 'issn' in json_line:\n",
    "            \n",
    "            if json_line['lang'] == 'en' :\n",
    "                \n",
    "                ## store paper info, later use to get the subject of the paper\n",
    "                paper_id.append(json_line['id'])\n",
    "                abstract.append(json_line['abstract'])\n",
    "\n",
    "                \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>95421</td>\n",
       "      <td>95421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>95421</td>\n",
       "      <td>95413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>55a6bcc065ce054aad738dc4</td>\n",
       "      <td>This article is one of ten reviews selected fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  \\\n",
       "count                      95421   \n",
       "unique                     95421   \n",
       "top     55a6bcc065ce054aad738dc4   \n",
       "freq                           1   \n",
       "\n",
       "                                                 abstract  \n",
       "count                                               95421  \n",
       "unique                                              95413  \n",
       "top     This article is one of ten reviews selected fr...  \n",
       "freq                                                    2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame()\n",
    "df['id'] = paper_id\n",
    "df['abstract'] = abstract\n",
    "#df.set_index('id')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53e99796b7602d9701f5d979</td>\n",
       "      <td>The pHealth 2015 Conference is the 12th in a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53e99796b7602d9701f613ec</td>\n",
       "      <td>A graphical model is a probability distributio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53e9979bb7602d9701f668c8</td>\n",
       "      <td>An inter-governmental body is encouraging the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53e997a2b7602d9701f74d6a</td>\n",
       "      <td>The most important results from the EU-sponsor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53e997a2b7602d9701f75614</td>\n",
       "      <td>The Nursing and Midwifery Council is seeking t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                                           abstract\n",
       "0  53e99796b7602d9701f5d979  The pHealth 2015 Conference is the 12th in a s...\n",
       "1  53e99796b7602d9701f613ec  A graphical model is a probability distributio...\n",
       "2  53e9979bb7602d9701f668c8  An inter-governmental body is encouraging the ...\n",
       "3  53e997a2b7602d9701f74d6a  The most important results from the EU-sponsor...\n",
       "4  53e997a2b7602d9701f75614  The Nursing and Midwifery Council is seeking t..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A graphical model is a probability distribution associated with a graph with the following properties: (1) the nodes in the graph represent the variables in the model, (2) separation in the graph implies conditional independence of the variables given the separating set, and (3) the probability distribution can be factored according to the graph. Graphical models are useful for researchers because they support efficient computation in models with many variables and provide a visualization of a complex model.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = pd.read_csv('paper_subject_match.csv',index_col = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_subject</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53e99784b7602d9701f3e13e</th>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99784b7602d9701f3e4f2</th>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9978db7602d9701f4f415</th>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99792b7602d9701f56a86</th>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99792b7602d9701f5b087</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          paper_subject\n",
       "id                                     \n",
       "53e99784b7602d9701f3e13e           13.0\n",
       "53e99784b7602d9701f3e4f2           13.0\n",
       "53e9978db7602d9701f4f415           13.0\n",
       "53e99792b7602d9701f56a86           27.0\n",
       "53e99792b7602d9701f5b087            NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = pd.merge(df, subject, on = ['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53e99796b7602d9701f5d979</td>\n",
       "      <td>The pHealth 2015 Conference is the 12th in a s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53e99796b7602d9701f613ec</td>\n",
       "      <td>A graphical model is a probability distributio...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53e9979bb7602d9701f668c8</td>\n",
       "      <td>An inter-governmental body is encouraging the ...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53e997a2b7602d9701f74d6a</td>\n",
       "      <td>The most important results from the EU-sponsor...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53e997a2b7602d9701f75614</td>\n",
       "      <td>The Nursing and Midwifery Council is seeking t...</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0  53e99796b7602d9701f5d979   \n",
       "1  53e99796b7602d9701f613ec   \n",
       "2  53e9979bb7602d9701f668c8   \n",
       "3  53e997a2b7602d9701f74d6a   \n",
       "4  53e997a2b7602d9701f75614   \n",
       "\n",
       "                                            abstract  paper_subject  \n",
       "0  The pHealth 2015 Conference is the 12th in a s...            NaN  \n",
       "1  A graphical model is a probability distributio...            NaN  \n",
       "2  An inter-governmental body is encouraging the ...           10.0  \n",
       "3  The most important results from the EU-sponsor...            NaN  \n",
       "4  The Nursing and Midwifery Council is seeking t...           29.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "abstract            0\n",
       "paper_subject    6180\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95421"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = tm.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = tm.drop(columns = ['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm['paper_subject'] = tm['paper_subject'].apply(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatenate all abstracts having the same subject(group by subject)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_all = tm.groupby('paper_subject').agg({'abstract':'-'.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_all.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_subject</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>An inter-governmental body is encouraging the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>The total variation (TV) regularization method...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>Technologies for automated detection of neonat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>Skeletal stem cells (SSCs) reside in the postn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>Despite the extensive application of Monte Car...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_subject                                           abstract\n",
       "0             10  An inter-governmental body is encouraging the ...\n",
       "1             11  The total variation (TV) regularization method...\n",
       "2             12  Technologies for automated detection of neonat...\n",
       "3             13  Skeletal stem cells (SSCs) reside in the postn...\n",
       "4             14  Despite the extensive application of Monte Car..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Processing the abstract:**\n",
    "- Tokenization: Split the text into sentences and the sentences into words. Lowercase the words and remove punctuation\n",
    "- Words that have fewer than 3 characters are removed\n",
    "- All stopwords are removed\n",
    "- lemmatized — words in third person to first person, verbs in past and future tenses to present\n",
    "- Stemmed — words are reduced to their root form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install gensim\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/yihuan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v')) #lemmatize as verb, default is noun\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of processing the words in the abstract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'graphical', 'model', 'is', 'a', 'probability', 'distribution', 'associated', 'with', 'a', 'graph', 'with', 'the', 'following', 'properties:', '(1)', 'the', 'nodes', 'in', 'the', 'graph', 'represent', 'the', 'variables', 'in', 'the', 'model,', '(2)', 'separation', 'in', 'the', 'graph', 'implies', 'conditional', 'independence', 'of', 'the', 'variables', 'given', 'the', 'separating', 'set,', 'and', '(3)', 'the', 'probability', 'distribution', 'can', 'be', 'factored', 'according', 'to', 'the', 'graph.', 'Graphical', 'models', 'are', 'useful', 'for', 'researchers', 'because', 'they', 'support', 'efficient', 'computation', 'in', 'models', 'with', 'many', 'variables', 'and', 'provide', 'a', 'visualization', 'of', 'a', 'complex', 'model.']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['graphic', 'model', 'probabl', 'distribut', 'associ', 'graph', 'follow', 'properti', 'nod', 'graph', 'repres', 'variabl', 'model', 'separ', 'graph', 'impli', 'condit', 'independ', 'variabl', 'give', 'separ', 'probabl', 'distribut', 'factor', 'accord', 'graph', 'graphic', 'model', 'use', 'research', 'support', 'effici', 'comput', 'model', 'variabl', 'provid', 'visual', 'complex', 'model']\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english') #Create a new instance of a language specific subclass\n",
    "doc_sample = df.iloc[1,1]\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words[:100])\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample[:1000]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real processing of all the abstract, **takes time!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = df['abstract'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['graphic',\n",
       " 'model',\n",
       " 'probabl',\n",
       " 'distribut',\n",
       " 'associ',\n",
       " 'graph',\n",
       " 'follow',\n",
       " 'properti',\n",
       " 'nod',\n",
       " 'graph',\n",
       " 'repres',\n",
       " 'variabl',\n",
       " 'model',\n",
       " 'separ',\n",
       " 'graph',\n",
       " 'impli',\n",
       " 'condit',\n",
       " 'independ',\n",
       " 'variabl',\n",
       " 'give',\n",
       " 'separ',\n",
       " 'probabl',\n",
       " 'distribut',\n",
       " 'factor',\n",
       " 'accord',\n",
       " 'graph',\n",
       " 'graphic',\n",
       " 'model',\n",
       " 'use',\n",
       " 'research',\n",
       " 'support',\n",
       " 'effici',\n",
       " 'comput',\n",
       " 'model',\n",
       " 'variabl',\n",
       " 'provid',\n",
       " 'visual',\n",
       " 'complex',\n",
       " 'model']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[1] #words processed in Economics, Econometrics and Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs) \n",
    "#Dictionary encapsulates the mapping between normalized words and their integer ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 academ\n",
      "1 accept\n",
      "2 acknowledg\n",
      "3 activ\n",
      "4 actuat\n",
      "5 adapt\n",
      "6 add\n",
      "7 addit\n",
      "8 address\n",
      "9 administr\n",
      "10 affair\n",
      "11 ahm\n",
      "12 aim\n",
      "13 allow\n",
      "14 analyt\n",
      "15 anim\n",
      "16 app\n",
      "17 applic\n",
      "18 approach\n",
      "19 area\n",
      "20 artifact\n",
      "21 aspect\n",
      "22 assist\n",
      "23 attende\n",
      "24 attract\n",
      "25 author\n",
      "26 autonom\n",
      "27 autonomi\n",
      "28 base\n",
      "29 basic\n",
      "30 benefit\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5)\n",
    "# How should we limit? I kept all instead of keep_n=100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "# for each subject, create a dictionary reporting words and how many times those words appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(105, 1),\n",
       " (111, 1),\n",
       " (137, 1),\n",
       " (174, 5),\n",
       " (229, 1),\n",
       " (241, 1),\n",
       " (243, 1),\n",
       " (275, 1),\n",
       " (306, 1),\n",
       " (307, 1),\n",
       " (308, 1),\n",
       " (309, 1),\n",
       " (310, 1),\n",
       " (311, 2),\n",
       " (312, 1),\n",
       " (313, 1),\n",
       " (314, 4),\n",
       " (315, 2),\n",
       " (316, 1),\n",
       " (317, 1),\n",
       " (318, 2),\n",
       " (319, 1),\n",
       " (320, 2),\n",
       " (321, 1),\n",
       " (322, 3),\n",
       " (323, 1)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus[1] #（id in dict, how many times of appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 105 (\"follow\") appears 1 time.\n",
      "Word 111 (\"give\") appears 1 time.\n",
      "Word 137 (\"independ\") appears 1 time.\n",
      "Word 174 (\"model\") appears 5 time.\n",
      "Word 229 (\"provid\") appears 1 time.\n",
      "Word 241 (\"repres\") appears 1 time.\n",
      "Word 243 (\"research\") appears 1 time.\n",
      "Word 275 (\"support\") appears 1 time.\n",
      "Word 306 (\"accord\") appears 1 time.\n",
      "Word 307 (\"associ\") appears 1 time.\n",
      "Word 308 (\"complex\") appears 1 time.\n",
      "Word 309 (\"comput\") appears 1 time.\n",
      "Word 310 (\"condit\") appears 1 time.\n",
      "Word 311 (\"distribut\") appears 2 time.\n",
      "Word 312 (\"effici\") appears 1 time.\n",
      "Word 313 (\"factor\") appears 1 time.\n",
      "Word 314 (\"graph\") appears 4 time.\n",
      "Word 315 (\"graphic\") appears 2 time.\n",
      "Word 316 (\"impli\") appears 1 time.\n",
      "Word 317 (\"nod\") appears 1 time.\n",
      "Word 318 (\"probabl\") appears 2 time.\n",
      "Word 319 (\"properti\") appears 1 time.\n",
      "Word 320 (\"separ\") appears 2 time.\n",
      "Word 321 (\"use\") appears 1 time.\n",
      "Word 322 (\"variabl\") appears 3 time.\n",
      "Word 323 (\"visual\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "# bag of words example in Economics, Econometrics and Finance\n",
    "bow_doc_1 = bow_corpus[1]\n",
    "\n",
    "for i in range(len(bow_doc_1)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_1[i][0], \n",
    "                                                     dictionary[bow_doc_1[i][0]], \n",
    "                                                     bow_doc_1[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.031218741596172533),\n",
      " (1, 0.04982103983796237),\n",
      " (2, 0.03811423887672271),\n",
      " (3, 0.029873541894316645),\n",
      " (4, 0.03962795262891248),\n",
      " (5, 0.02123700186770666),\n",
      " (6, 0.02582993724132953),\n",
      " (7, 0.012293122745157729),\n",
      " (8, 0.06231939112626948),\n",
      " (9, 0.04483022785047973),\n",
      " (10, 0.04469120954853038),\n",
      " (11, 0.01758680692215315),\n",
      " (12, 0.018419065305608443),\n",
      " (13, 0.026064491033766783),\n",
      " (14, 0.02007487533638507),\n",
      " (15, 0.05080873121934377),\n",
      " (16, 0.016249582120108512),\n",
      " (17, 0.014178756559191681),\n",
      " (18, 0.03312595636010068),\n",
      " (19, 0.040543055299211914),\n",
      " (20, 0.023701054678215133),\n",
      " (21, 0.02462693745959774),\n",
      " (22, 0.049090113534634675),\n",
      " (23, 0.027861278949898927),\n",
      " (24, 0.050441322306727814),\n",
      " (25, 0.034400911418692115),\n",
      " (26, 0.04036349675488041),\n",
      " (27, 0.009368508163015862),\n",
      " (28, 0.05370917118269671),\n",
      " (29, 0.0409823556043125),\n",
      " (30, 0.09845747366513535),\n",
      " (31, 0.018103344268861492),\n",
      " (32, 0.06811812764524715),\n",
      " (33, 0.037227544001717496),\n",
      " (34, 0.04483133973949594),\n",
      " (35, 0.09620898312796),\n",
      " (36, 0.025781820707857908),\n",
      " (37, 0.1342553961951169),\n",
      " (38, 0.023087681559961985),\n",
      " (39, 0.07453768676895896),\n",
      " (40, 0.012549714828634324),\n",
      " (41, 0.04700015058381268),\n",
      " (42, 0.01932193436748497),\n",
      " (43, 0.08745473525923611),\n",
      " (44, 0.021433070901678772),\n",
      " (45, 0.039082918120377924),\n",
      " (46, 0.015146216981832128),\n",
      " (47, 0.031024552839207666),\n",
      " (48, 0.11110659303382286),\n",
      " (49, 0.042768847229572346),\n",
      " (50, 0.03891102166897525),\n",
      " (51, 0.05997897321071238),\n",
      " (52, 0.031218741596172533),\n",
      " (53, 0.04131592422965989),\n",
      " (54, 0.4198528124749867),\n",
      " (55, 0.03145049938300789),\n",
      " (56, 0.026018422452309425),\n",
      " (57, 0.03350011540046656),\n",
      " (58, 0.010367663529387791),\n",
      " (59, 0.020693937236765606),\n",
      " (60, 0.07086433179214273),\n",
      " (61, 0.05415222062222268),\n",
      " (62, 0.01977903158734029),\n",
      " (63, 0.023357894209677606),\n",
      " (64, 0.019563388694833133),\n",
      " (65, 0.023830513120191046),\n",
      " (66, 0.0714419238303358),\n",
      " (67, 0.043211433553885466),\n",
      " (68, 0.019010153625846096),\n",
      " (69, 0.02397330785135685),\n",
      " (70, 0.02795874914258764),\n",
      " (71, 0.029773318751897062),\n",
      " (72, 0.019618347263223514),\n",
      " (73, 0.0447865575179504),\n",
      " (74, 0.0388828127184058),\n",
      " (75, 0.0359757240717324),\n",
      " (76, 0.043356137882500125),\n",
      " (77, 0.02278650176751177),\n",
      " (78, 0.040158881687082766),\n",
      " (79, 0.032610094330385815),\n",
      " (80, 0.14646450714103304),\n",
      " (81, 0.00738360328682468),\n",
      " (82, 0.049003547251120064),\n",
      " (83, 0.060469861155352904),\n",
      " (84, 0.021062660754245097),\n",
      " (85, 0.061041571936526436),\n",
      " (86, 0.04393468556941668),\n",
      " (87, 0.026942284017877946),\n",
      " (88, 0.04032817757107279),\n",
      " (89, 0.02666574895958445),\n",
      " (90, 0.06162995249801021),\n",
      " (91, 0.02145753292313468),\n",
      " (92, 0.03653347450138029),\n",
      " (93, 0.06640004156377553),\n",
      " (94, 0.08407889632938095),\n",
      " (95, 0.11737963536333376),\n",
      " (96, 0.028463923467353495),\n",
      " (97, 0.04388202588258911),\n",
      " (98, 0.03129635004443371),\n",
      " (99, 0.038996396889526413),\n",
      " (100, 0.028773103235818935),\n",
      " (101, 0.07759783821140669),\n",
      " (102, 0.019106302230595937),\n",
      " (103, 0.02788167686222986),\n",
      " (104, 0.0352649400470069),\n",
      " (105, 0.011951183044726454),\n",
      " (106, 0.03902510845110764),\n",
      " (107, 0.024069168534835497),\n",
      " (108, 0.027680545570073895),\n",
      " (109, 0.05706143758380551),\n",
      " (110, 0.01662681541628558),\n",
      " (111, 0.03795085289122647),\n",
      " (112, 0.022193677877134544),\n",
      " (113, 0.04462227055001914),\n",
      " (114, 0.03959643307995624),\n",
      " (115, 0.010978061077395278),\n",
      " (116, 0.022765682939344604),\n",
      " (117, 0.03438688369842793),\n",
      " (118, 0.02544769556398309),\n",
      " (119, 0.037206856310763314),\n",
      " (120, 0.04626795014684452),\n",
      " (121, 0.17260457789243985),\n",
      " (122, 0.02741860607802033),\n",
      " (123, 0.020145237640729702),\n",
      " (124, 0.026264541186274196),\n",
      " (125, 0.012106172793456023),\n",
      " (126, 0.021168140395549772),\n",
      " (127, 0.027380689880939214),\n",
      " (128, 0.04210083343836715),\n",
      " (129, 0.06461757673803402),\n",
      " (130, 0.03338438253320723),\n",
      " (131, 0.05334842696931643),\n",
      " (132, 0.02055314082089875),\n",
      " (133, 0.011612132027549038),\n",
      " (134, 0.01195852074221391),\n",
      " (135, 0.00918813833465984),\n",
      " (136, 0.029420375864531185),\n",
      " (137, 0.034822692855415255),\n",
      " (138, 0.0262919188982508),\n",
      " (139, 0.09932689090212792),\n",
      " (140, 0.034706480497024385),\n",
      " (141, 0.12416483397702566),\n",
      " (142, 0.023032083276717748),\n",
      " (143, 0.050353739472935186),\n",
      " (144, 0.03555087988599181),\n",
      " (145, 0.024331707342902242),\n",
      " (146, 0.08431455888968692),\n",
      " (147, 0.11085463891889082),\n",
      " (148, 0.0144380508845066),\n",
      " (149, 0.053422251824453953),\n",
      " (150, 0.05992123781228155),\n",
      " (151, 0.040803149053729504),\n",
      " (152, 0.04993752981585622),\n",
      " (153, 0.07598103311564809),\n",
      " (154, 0.08183582588884092),\n",
      " (155, 0.020022525323109372),\n",
      " (156, 0.041193919295424375),\n",
      " (157, 0.021678068941250062),\n",
      " (158, 0.03669769926791413),\n",
      " (159, 0.01721022595663453),\n",
      " (160, 0.1105531484079186),\n",
      " (161, 0.05386479227169802),\n",
      " (162, 0.03140130327090695),\n",
      " (163, 0.033953393670523684),\n",
      " (164, 0.028685721849027603),\n",
      " (165, 0.1270066410124448),\n",
      " (166, 0.050140652475441666),\n",
      " (167, 0.02607220124391743),\n",
      " (168, 0.07325301453258831),\n",
      " (169, 0.04856363859814354),\n",
      " (170, 0.0246578374944089),\n",
      " (171, 0.05369657981718321),\n",
      " (172, 0.031322428575963894),\n",
      " (173, 0.053096796277048774),\n",
      " (174, 0.010653282971858523),\n",
      " (175, 0.022298073155592336),\n",
      " (176, 0.07175593997421803),\n",
      " (177, 0.021983686970752033),\n",
      " (178, 0.02416027584550864),\n",
      " (179, 0.014643042530689904),\n",
      " (180, 0.01991115102550892),\n",
      " (181, 0.05369657981718321),\n",
      " (182, 0.049815116799844066),\n",
      " (183, 0.041153758823342254),\n",
      " (184, 0.04458755772336884),\n",
      " (185, 0.018161870638423634),\n",
      " (186, 0.047253441664584235),\n",
      " (187, 0.07078526244012785),\n",
      " (188, 0.03975559511513123),\n",
      " (189, 0.0542829597844596),\n",
      " (190, 0.03253619420906014),\n",
      " (191, 0.06141616884403566),\n",
      " (192, 0.027645983905942483),\n",
      " (193, 0.04355076110499346),\n",
      " (194, 0.01564441230278521),\n",
      " (195, 0.043378864653590775),\n",
      " (196, 0.05123960429975592),\n",
      " (197, 0.034363625823013215),\n",
      " (198, 0.047409541160798506),\n",
      " (199, 0.010284188796545222),\n",
      " (200, 0.11108483405840018),\n",
      " (201, 0.042385250234091065),\n",
      " (202, 0.03307306397567789),\n",
      " (203, 0.0486912810843623),\n",
      " (204, 0.02753371154603668),\n",
      " (205, 0.07754239094384391),\n",
      " (206, 0.056451770628776335),\n",
      " (207, 0.041193919295424375),\n",
      " (208, 0.11290354125755267),\n",
      " (209, 0.03293852357643473),\n",
      " (210, 0.1587189532461641),\n",
      " (211, 0.023284157706058593),\n",
      " (212, 0.036784117633723475),\n",
      " (213, 0.031516964833755524),\n",
      " (214, 0.016105811299327234),\n",
      " (215, 0.04409483011124967),\n",
      " (216, 0.08715191122498345),\n",
      " (217, 0.03978790463098805),\n",
      " (218, 0.03530666680243578),\n",
      " (219, 0.01526485787374915),\n",
      " (220, 0.02791752927442591),\n",
      " (221, 0.022360664075202638),\n",
      " (222, 0.04233696734977184),\n",
      " (223, 0.07305546071214998),\n",
      " (224, 0.013086470866144556),\n",
      " (225, 0.05297279913799235),\n",
      " (226, 0.04141805350370412),\n",
      " (227, 0.02626006838295642),\n",
      " (228, 0.03444317868435971),\n",
      " (229, 0.032304679160940174),\n",
      " (230, 0.04762441888893762),\n",
      " (231, 0.043461918657001594),\n",
      " (232, 0.02349607722517073),\n",
      " (233, 0.03482873242911894),\n",
      " (234, 0.015004038762609093),\n",
      " (235, 0.040690392797954895),\n",
      " (236, 0.015062491255705066),\n",
      " (237, 0.018861002110920354),\n",
      " (238, 0.035034945810259226),\n",
      " (239, 0.020008485107050035),\n",
      " (240, 0.011035813937073775),\n",
      " (241, 0.017975767689615785),\n",
      " (242, 0.02895757276885856),\n",
      " (243, 0.030021939322075017),\n",
      " (244, 0.013037139069791906),\n",
      " (245, 0.04334272558599842),\n",
      " (246, 0.013242161196096535),\n",
      " (247, 0.012830776272928257),\n",
      " (248, 0.02286576315944903),\n",
      " (249, 0.03707793731500135),\n",
      " (250, 0.02809456381690765),\n",
      " (251, 0.11890316886708781),\n",
      " (252, 0.03871610338511045),\n",
      " (253, 0.06356542302796177),\n",
      " (254, 0.030166992552393482),\n",
      " (255, 0.10702074305987613),\n",
      " (256, 0.04628752717389423),\n",
      " (257, 0.09046012854198397),\n",
      " (258, 0.0889140057254578),\n",
      " (259, 0.020043007011724727),\n",
      " (260, 0.02497526918185779),\n",
      " (261, 0.020851592261471017),\n",
      " (262, 0.1118168874180093),\n",
      " (263, 0.030958357290372815),\n",
      " (264, 0.08763376047122579),\n",
      " (265, 0.02826574692100415),\n",
      " (266, 0.10794473525361706),\n",
      " (267, 0.0778384418982461),\n",
      " (268, 0.04625198013663323),\n",
      " (269, 0.03674625077146414),\n",
      " (270, 0.025170158923870395),\n",
      " (271, 0.08496582950554726),\n",
      " (272, 0.027989837956476225),\n",
      " (273, 0.09874081407810124),\n",
      " (274, 0.03679818617258944),\n",
      " (275, 0.09303092513284855),\n",
      " (276, 0.07244509962667872),\n",
      " (277, 0.06653935883465525),\n",
      " (278, 0.0770538136144782),\n",
      " (279, 0.030909152968098336),\n",
      " (280, 0.017249362293727755),\n",
      " (281, 0.19703056846721936),\n",
      " (282, 0.05099031322466109),\n",
      " (283, 0.01543589659369604),\n",
      " (284, 0.047516084659545266),\n",
      " (285, 0.08238783859084875),\n",
      " (286, 0.010171925438767028),\n",
      " (287, 0.058482632316353485),\n",
      " (288, 0.023325065714062985),\n",
      " (289, 0.02374929741007259),\n",
      " (290, 0.026240241437402296),\n",
      " (291, 0.04422343809974676),\n",
      " (292, 0.03511288793186937),\n",
      " (293, 0.01511936265871518),\n",
      " (294, 0.0240325209163568),\n",
      " (295, 0.015603230231139397),\n",
      " (296, 0.04922873683256768),\n",
      " (297, 0.11290354125755267),\n",
      " (298, 0.03149008890218169),\n",
      " (299, 0.022816692618572602),\n",
      " (300, 0.0454244691680355),\n",
      " (301, 0.04228904344932491),\n",
      " (302, 0.017927615965456854),\n",
      " (303, 0.016861825659756243),\n",
      " (304, 0.0416964387254881),\n",
      " (305, 0.04957219898954545)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running LDA using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.011*\"increas\" + 0.009*\"concentr\" + 0.009*\"effect\" + 0.008*\"plant\" + 0.008*\"level\" + 0.008*\"differ\" + 0.007*\"product\" + 0.007*\"signific\" + 0.007*\"diet\" + 0.007*\"speci\"\n",
      "Topic: 1 \n",
      "Words: 0.040*\"cell\" + 0.019*\"express\" + 0.014*\"activ\" + 0.011*\"induc\" + 0.010*\"effect\" + 0.008*\"level\" + 0.008*\"increas\" + 0.008*\"cancer\" + 0.008*\"regul\" + 0.008*\"protein\"\n",
      "Topic: 2 \n",
      "Words: 0.024*\"protein\" + 0.014*\"activ\" + 0.011*\"bind\" + 0.009*\"structur\" + 0.008*\"acid\" + 0.007*\"compound\" + 0.007*\"interact\" + 0.007*\"complex\" + 0.006*\"membran\" + 0.006*\"function\"\n",
      "Topic: 3 \n",
      "Words: 0.015*\"health\" + 0.008*\"particip\" + 0.008*\"children\" + 0.007*\"care\" + 0.007*\"research\" + 0.006*\"effect\" + 0.006*\"intervent\" + 0.006*\"relat\" + 0.005*\"provid\" + 0.005*\"data\"\n",
      "Topic: 4 \n",
      "Words: 0.015*\"model\" + 0.012*\"method\" + 0.011*\"imag\" + 0.009*\"base\" + 0.009*\"data\" + 0.007*\"propos\" + 0.007*\"result\" + 0.007*\"perform\" + 0.006*\"approach\" + 0.006*\"measur\"\n",
      "Topic: 5 \n",
      "Words: 0.008*\"surfac\" + 0.008*\"high\" + 0.007*\"properti\" + 0.007*\"extract\" + 0.006*\"result\" + 0.006*\"effect\" + 0.006*\"materi\" + 0.006*\"method\" + 0.005*\"temperatur\" + 0.005*\"structur\"\n",
      "Topic: 6 \n",
      "Words: 0.012*\"pain\" + 0.012*\"measur\" + 0.010*\"time\" + 0.009*\"signific\" + 0.008*\"pressur\" + 0.008*\"blood\" + 0.008*\"perform\" + 0.008*\"differ\" + 0.008*\"arteri\" + 0.008*\"mean\"\n",
      "Topic: 7 \n",
      "Words: 0.010*\"group\" + 0.010*\"brain\" + 0.007*\"muscl\" + 0.007*\"control\" + 0.007*\"function\" + 0.006*\"signific\" + 0.006*\"neuron\" + 0.006*\"bone\" + 0.006*\"differ\" + 0.006*\"increas\"\n",
      "Topic: 8 \n",
      "Words: 0.044*\"patient\" + 0.013*\"group\" + 0.012*\"associ\" + 0.011*\"risk\" + 0.011*\"year\" + 0.010*\"treatment\" + 0.010*\"clinic\" + 0.009*\"signific\" + 0.009*\"diseas\" + 0.007*\"outcom\"\n",
      "Topic: 9 \n",
      "Words: 0.023*\"gene\" + 0.009*\"genet\" + 0.009*\"sequenc\" + 0.009*\"speci\" + 0.009*\"identifi\" + 0.009*\"genom\" + 0.007*\"mutat\" + 0.007*\"analysi\" + 0.006*\"isol\" + 0.006*\"develop\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running LDA using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.006*\"speci\" + 0.006*\"gene\" + 0.004*\"genom\" + 0.004*\"sequenc\" + 0.004*\"genet\" + 0.003*\"mutat\" + 0.003*\"cell\" + 0.003*\"plant\" + 0.002*\"protein\" + 0.002*\"popul\"\n",
      "Topic: 1 Word: 0.004*\"cognit\" + 0.004*\"task\" + 0.004*\"research\" + 0.003*\"particip\" + 0.003*\"memori\" + 0.003*\"learn\" + 0.003*\"train\" + 0.003*\"placebo\" + 0.003*\"social\" + 0.003*\"health\"\n",
      "Topic: 2 Word: 0.004*\"surfac\" + 0.004*\"structur\" + 0.004*\"electron\" + 0.003*\"materi\" + 0.003*\"film\" + 0.003*\"method\" + 0.003*\"energi\" + 0.003*\"layer\" + 0.003*\"suicid\" + 0.003*\"graphen\"\n",
      "Topic: 3 Word: 0.014*\"asthma\" + 0.009*\"alcohol\" + 0.009*\"macrophag\" + 0.008*\"platelet\" + 0.008*\"fibrosi\" + 0.007*\"arthriti\" + 0.007*\"drink\" + 0.007*\"cytokin\" + 0.007*\"inflamm\" + 0.007*\"sepsi\"\n",
      "Topic: 4 Word: 0.006*\"optic\" + 0.006*\"propos\" + 0.005*\"power\" + 0.004*\"mode\" + 0.004*\"imag\" + 0.004*\"laser\" + 0.004*\"method\" + 0.004*\"fiber\" + 0.004*\"frequenc\" + 0.004*\"sensor\"\n",
      "Topic: 5 Word: 0.006*\"acid\" + 0.006*\"activ\" + 0.006*\"compound\" + 0.005*\"protein\" + 0.004*\"product\" + 0.004*\"cell\" + 0.004*\"bind\" + 0.003*\"plant\" + 0.003*\"oxid\" + 0.003*\"extract\"\n",
      "Topic: 6 Word: 0.012*\"cervic\" + 0.011*\"bone\" + 0.011*\"pregnanc\" + 0.010*\"gastric\" + 0.010*\"fractur\" + 0.009*\"matern\" + 0.008*\"sperm\" + 0.007*\"cyst\" + 0.006*\"arthroplasti\" + 0.006*\"oocyt\"\n",
      "Topic: 7 Word: 0.010*\"patient\" + 0.005*\"risk\" + 0.004*\"group\" + 0.004*\"year\" + 0.004*\"associ\" + 0.004*\"health\" + 0.003*\"treatment\" + 0.003*\"care\" + 0.003*\"diseas\" + 0.003*\"clinic\"\n",
      "Topic: 8 Word: 0.014*\"cell\" + 0.008*\"express\" + 0.008*\"tumor\" + 0.007*\"cancer\" + 0.005*\"mice\" + 0.005*\"induc\" + 0.004*\"regul\" + 0.004*\"protein\" + 0.004*\"activ\" + 0.004*\"tissu\"\n",
      "Topic: 9 Word: 0.007*\"transplant\" + 0.006*\"pancreat\" + 0.005*\"prostat\" + 0.005*\"nanoparticl\" + 0.005*\"bleed\" + 0.004*\"graft\" + 0.004*\"aureus\" + 0.004*\"drug\" + 0.004*\"implant\" + 0.004*\"resect\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify sample document using LDA Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['graphic',\n",
       " 'model',\n",
       " 'probabl',\n",
       " 'distribut',\n",
       " 'associ',\n",
       " 'graph',\n",
       " 'follow',\n",
       " 'properti',\n",
       " 'nod',\n",
       " 'graph',\n",
       " 'repres',\n",
       " 'variabl',\n",
       " 'model',\n",
       " 'separ',\n",
       " 'graph',\n",
       " 'impli',\n",
       " 'condit',\n",
       " 'independ',\n",
       " 'variabl',\n",
       " 'give',\n",
       " 'separ',\n",
       " 'probabl',\n",
       " 'distribut',\n",
       " 'factor',\n",
       " 'accord',\n",
       " 'graph',\n",
       " 'graphic',\n",
       " 'model',\n",
       " 'use',\n",
       " 'research',\n",
       " 'support',\n",
       " 'effici',\n",
       " 'comput',\n",
       " 'model',\n",
       " 'variabl',\n",
       " 'provid',\n",
       " 'visual',\n",
       " 'complex',\n",
       " 'model']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.977489709854126\t \n",
      "Topic: 0.015*\"model\" + 0.012*\"method\" + 0.011*\"imag\" + 0.009*\"base\" + 0.009*\"data\" + 0.007*\"propos\" + 0.007*\"result\" + 0.007*\"perform\" + 0.006*\"approach\" + 0.006*\"measur\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[1]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.4956255853176117\t \n",
      "Topic: 0.004*\"cognit\" + 0.004*\"task\" + 0.004*\"research\" + 0.003*\"particip\" + 0.003*\"memori\" + 0.003*\"learn\" + 0.003*\"train\" + 0.003*\"placebo\" + 0.003*\"social\" + 0.003*\"health\"\n",
      "\n",
      "Score: 0.4843655526638031\t \n",
      "Topic: 0.004*\"surfac\" + 0.004*\"structur\" + 0.004*\"electron\" + 0.003*\"materi\" + 0.003*\"film\" + 0.003*\"method\" + 0.003*\"energi\" + 0.003*\"layer\" + 0.003*\"suicid\" + 0.003*\"graphen\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[1]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to estimate for subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_subject = tm_all['abstract'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['consid',\n",
       " 'problem',\n",
       " 'estim',\n",
       " 'local',\n",
       " 'sensor',\n",
       " 'paramet',\n",
       " 'local',\n",
       " 'paramet',\n",
       " 'sensor',\n",
       " 'observ',\n",
       " 'relat',\n",
       " 'linear',\n",
       " 'stochast',\n",
       " 'model',\n",
       " 'studi',\n",
       " 'gaussian',\n",
       " 'product',\n",
       " 'algorithm',\n",
       " 'wireless',\n",
       " 'network',\n",
       " 'gspawn',\n",
       " 'procedur',\n",
       " 'compar',\n",
       " 'popular',\n",
       " 'diffus',\n",
       " 'strategi',\n",
       " 'perform',\n",
       " 'network',\n",
       " 'paramet',\n",
       " 'estim',\n",
       " 'communic',\n",
       " 'cost',\n",
       " 'sensor',\n",
       " 'increas',\n",
       " 'increas',\n",
       " 'network',\n",
       " 'densiti',\n",
       " 'gspawn',\n",
       " 'allow',\n",
       " 'sensor',\n",
       " 'broadcast',\n",
       " 'messag',\n",
       " 'size',\n",
       " 'depend',\n",
       " 'network',\n",
       " 'size',\n",
       " 'densiti',\n",
       " 'make',\n",
       " 'suitabl',\n",
       " 'applic',\n",
       " 'wireless',\n",
       " 'sensor',\n",
       " 'network',\n",
       " 'gspawn',\n",
       " 'converg',\n",
       " 'mean',\n",
       " 'mean',\n",
       " 'squar',\n",
       " 'stabil',\n",
       " 'technic',\n",
       " 'suffici',\n",
       " 'condit',\n",
       " 'applic',\n",
       " 'gspawn',\n",
       " 'network',\n",
       " 'local',\n",
       " 'problem',\n",
       " 'line',\n",
       " 'sight',\n",
       " 'environ',\n",
       " 'numer',\n",
       " 'result',\n",
       " 'suggest',\n",
       " 'gspawn',\n",
       " 'converg',\n",
       " 'faster',\n",
       " 'general',\n",
       " 'diffus',\n",
       " 'method',\n",
       " 'lower',\n",
       " 'communic',\n",
       " 'cost',\n",
       " 'sensor',\n",
       " 'compar',\n",
       " 'root',\n",
       " 'mean',\n",
       " 'squar',\n",
       " 'error',\n",
       " 'express',\n",
       " 'clone',\n",
       " 'play',\n",
       " 'import',\n",
       " 'role',\n",
       " 'facial',\n",
       " 'express',\n",
       " 'synthesi',\n",
       " 'paper',\n",
       " 'novel',\n",
       " 'algorithm',\n",
       " 'propos',\n",
       " 'facial',\n",
       " 'express',\n",
       " 'clone',\n",
       " 'propos',\n",
       " 'algorithm',\n",
       " 'introduc',\n",
       " 'elast',\n",
       " 'model',\n",
       " 'balanc',\n",
       " 'global',\n",
       " 'local',\n",
       " 'warp',\n",
       " 'effect',\n",
       " 'impact',\n",
       " 'facial',\n",
       " 'featur',\n",
       " 'divers',\n",
       " 'peopl',\n",
       " 'minim',\n",
       " 'effect',\n",
       " 'geometr',\n",
       " 'warp',\n",
       " 'result',\n",
       " 'achiev',\n",
       " 'furthermor',\n",
       " 'muscl',\n",
       " 'distribut',\n",
       " 'base',\n",
       " 'model',\n",
       " 'propos',\n",
       " 'util',\n",
       " 'muscl',\n",
       " 'distribut',\n",
       " 'human',\n",
       " 'face',\n",
       " 'result',\n",
       " 'accur',\n",
       " 'facial',\n",
       " 'illumin',\n",
       " 'detail',\n",
       " 'addit',\n",
       " 'propos',\n",
       " 'distanc',\n",
       " 'base',\n",
       " 'metric',\n",
       " 'automat',\n",
       " 'select',\n",
       " 'optim',\n",
       " 'paramet',\n",
       " 'global',\n",
       " 'local',\n",
       " 'warp',\n",
       " 'effect',\n",
       " 'elast',\n",
       " 'model',\n",
       " 'suitabl',\n",
       " 'balanc',\n",
       " 'experiment',\n",
       " 'result',\n",
       " 'propos',\n",
       " 'algorithm',\n",
       " 'outperform',\n",
       " 'exist',\n",
       " 'method',\n",
       " 'elsevi',\n",
       " 'right',\n",
       " 'reserv',\n",
       " 'paper',\n",
       " 'consid',\n",
       " 'wireless',\n",
       " 'power',\n",
       " 'cooper',\n",
       " 'communic',\n",
       " 'network',\n",
       " 'consist',\n",
       " 'hybrid',\n",
       " 'access',\n",
       " 'point',\n",
       " 'sourc',\n",
       " 'relay',\n",
       " 'contrast',\n",
       " 'convent',\n",
       " 'cooper',\n",
       " 'network',\n",
       " 'sourc',\n",
       " 'relay',\n",
       " 'consid',\n",
       " 'network',\n",
       " 'emb',\n",
       " 'energi',\n",
       " 'suppli',\n",
       " 'need',\n",
       " 'reli',\n",
       " 'energi',\n",
       " 'harvest',\n",
       " 'signal',\n",
       " 'broadcast',\n",
       " 'cooper',\n",
       " 'inform',\n",
       " 'transmiss',\n",
       " 'base',\n",
       " 'node',\n",
       " 'refer',\n",
       " 'model',\n",
       " 'propos',\n",
       " 'harvest',\n",
       " 'cooper',\n",
       " 'protocol',\n",
       " 'sourc',\n",
       " 'relay',\n",
       " 'harvest',\n",
       " 'energi',\n",
       " 'downlink',\n",
       " 'work',\n",
       " 'cooper',\n",
       " 'uplink',\n",
       " 'sourc',\n",
       " 'inform',\n",
       " 'transmiss',\n",
       " 'consid',\n",
       " 'delay',\n",
       " 'limit',\n",
       " 'transmiss',\n",
       " 'mode',\n",
       " 'approxim',\n",
       " 'close',\n",
       " 'form',\n",
       " 'express',\n",
       " 'averag',\n",
       " 'throughput',\n",
       " 'propos',\n",
       " 'protocol',\n",
       " 'deriv',\n",
       " 'rayleigh',\n",
       " 'fade',\n",
       " 'channel',\n",
       " 'subsequ',\n",
       " 'analysi',\n",
       " 'extend',\n",
       " 'multi',\n",
       " 'relay',\n",
       " 'scenario',\n",
       " 'approxim',\n",
       " 'throughput',\n",
       " 'protocol',\n",
       " 'popular',\n",
       " 'relay',\n",
       " 'select',\n",
       " 'scheme',\n",
       " 'deriv',\n",
       " 'asymptot',\n",
       " 'analys',\n",
       " 'throughput',\n",
       " 'perform',\n",
       " 'consid',\n",
       " 'scheme',\n",
       " 'high',\n",
       " 'signal',\n",
       " 'nois',\n",
       " 'radio',\n",
       " 'provid',\n",
       " 'theoret',\n",
       " 'result',\n",
       " 'valid',\n",
       " 'numer',\n",
       " 'simul',\n",
       " 'impact',\n",
       " 'paramet',\n",
       " 'time',\n",
       " 'alloc',\n",
       " 'relay',\n",
       " 'number',\n",
       " 'relay',\n",
       " 'posit',\n",
       " 'throughput',\n",
       " 'perform',\n",
       " 'extens',\n",
       " 'investig',\n",
       " 'paper',\n",
       " 'propos',\n",
       " 'crowdsourc',\n",
       " 'base',\n",
       " 'framework',\n",
       " 'myopic',\n",
       " 'target',\n",
       " 'track',\n",
       " 'design',\n",
       " 'optim',\n",
       " 'incent',\n",
       " 'compat',\n",
       " 'mechan',\n",
       " 'wireless',\n",
       " 'sensor',\n",
       " 'network',\n",
       " 'contain',\n",
       " 'sensor',\n",
       " 'selfish',\n",
       " 'profit',\n",
       " 'motiv',\n",
       " 'typic',\n",
       " 'wsns',\n",
       " 'limit',\n",
       " 'bandwidth',\n",
       " 'fusion',\n",
       " 'center',\n",
       " 'distribut',\n",
       " 'total',\n",
       " 'number',\n",
       " 'bit',\n",
       " 'transmit',\n",
       " 'sensor',\n",
       " 'sensor',\n",
       " 'formul',\n",
       " 'consid',\n",
       " 'conduct',\n",
       " 'auction',\n",
       " 'solicit',\n",
       " 'bid',\n",
       " 'selfish',\n",
       " 'sensor',\n",
       " 'reflect',\n",
       " 'valu',\n",
       " 'energi',\n",
       " 'cost',\n",
       " 'furthermor',\n",
       " 'ration',\n",
       " 'truth',\n",
       " 'sensor',\n",
       " 'guarante',\n",
       " 'model',\n",
       " 'final',\n",
       " 'problem',\n",
       " 'formul',\n",
       " 'multipl',\n",
       " 'choic',\n",
       " 'knapsack',\n",
       " 'problem',\n",
       " 'mckp',\n",
       " 'solv',\n",
       " 'dynam',\n",
       " 'program',\n",
       " 'method',\n",
       " 'pseudo',\n",
       " 'polynomi',\n",
       " 'time',\n",
       " 'simul',\n",
       " 'result',\n",
       " 'effect',\n",
       " 'propos',\n",
       " 'approach',\n",
       " 'term',\n",
       " 'track',\n",
       " 'perform',\n",
       " 'lifetim',\n",
       " 'sensor',\n",
       " 'network',\n",
       " 'present',\n",
       " 'joint',\n",
       " 'channel',\n",
       " 'power',\n",
       " 'alloc',\n",
       " 'framework',\n",
       " 'downlink',\n",
       " 'transmiss',\n",
       " 'orthogon',\n",
       " 'frequenc',\n",
       " 'divis',\n",
       " 'multipl',\n",
       " 'access',\n",
       " 'ofdma',\n",
       " 'base',\n",
       " 'cellular',\n",
       " 'network',\n",
       " 'compos',\n",
       " 'macrocel',\n",
       " 'overlay',\n",
       " 'small',\n",
       " 'cell',\n",
       " 'framework',\n",
       " 'resourc',\n",
       " 'alloc',\n",
       " 'problem',\n",
       " 'macrocel',\n",
       " 'small',\n",
       " 'cell',\n",
       " 'formul',\n",
       " 'optim',\n",
       " 'problem',\n",
       " 'macrocel',\n",
       " 'formul',\n",
       " 'problem',\n",
       " 'awar',\n",
       " 'exist',\n",
       " 'small',\n",
       " 'cell',\n",
       " 'tier',\n",
       " 'problem',\n",
       " 'macrocel',\n",
       " 'perform',\n",
       " 'satisfi',\n",
       " 'data',\n",
       " 'rate',\n",
       " 'requir',\n",
       " 'macro',\n",
       " 'user',\n",
       " 'equip',\n",
       " 'mue',\n",
       " 'maxim',\n",
       " 'toler',\n",
       " 'interfer',\n",
       " 'small',\n",
       " 'cell',\n",
       " 'tier',\n",
       " 'alloc',\n",
       " 'channel',\n",
       " 'problem',\n",
       " 'macrocel',\n",
       " 'show',\n",
       " 'mix',\n",
       " 'integ',\n",
       " 'nonlinear',\n",
       " 'problem',\n",
       " 'minlp',\n",
       " 'prove',\n",
       " 'macrocel',\n",
       " 'solv',\n",
       " 'altern',\n",
       " 'optim',\n",
       " 'problem',\n",
       " 'yield',\n",
       " 'optim',\n",
       " 'solut',\n",
       " 'reduc',\n",
       " 'complex',\n",
       " 'small',\n",
       " 'cell',\n",
       " 'follow',\n",
       " 'idea',\n",
       " 'tier',\n",
       " 'awar',\n",
       " 'formul',\n",
       " 'optim',\n",
       " 'problem',\n",
       " 'account',\n",
       " 'admiss',\n",
       " 'control',\n",
       " 'aim',\n",
       " 'maxim',\n",
       " 'number',\n",
       " 'admit',\n",
       " 'user',\n",
       " 'simultan',\n",
       " 'minim',\n",
       " 'consum',\n",
       " 'bandwidth',\n",
       " 'similar',\n",
       " 'macrocel',\n",
       " 'optim',\n",
       " 'problem',\n",
       " 'small',\n",
       " 'cell',\n",
       " 'problem',\n",
       " 'show',\n",
       " 'minlp',\n",
       " 'obtain',\n",
       " 'optim',\n",
       " 'solut',\n",
       " 'minlp',\n",
       " 'problem',\n",
       " 'reli',\n",
       " 'convex',\n",
       " 'relax',\n",
       " 'addit',\n",
       " 'employ',\n",
       " 'dual',\n",
       " 'decomposit',\n",
       " 'techniqu',\n",
       " 'distribut',\n",
       " 'solut',\n",
       " 'small',\n",
       " 'cell',\n",
       " 'tier',\n",
       " 'numer',\n",
       " 'result',\n",
       " 'confirm',\n",
       " 'perform',\n",
       " 'gain',\n",
       " 'propos',\n",
       " 'formul',\n",
       " 'macrocel',\n",
       " 'tradit',\n",
       " 'resourc',\n",
       " 'alloc',\n",
       " 'base',\n",
       " 'minim',\n",
       " 'transmiss',\n",
       " 'power',\n",
       " 'show',\n",
       " 'formul',\n",
       " 'base',\n",
       " 'convex',\n",
       " 'relax',\n",
       " 'yield',\n",
       " 'similar',\n",
       " 'behavior',\n",
       " 'minlp',\n",
       " 'formul',\n",
       " 'distribut',\n",
       " 'solut',\n",
       " 'converg',\n",
       " 'solut',\n",
       " 'obtain',\n",
       " 'solv',\n",
       " 'correspond',\n",
       " 'convex',\n",
       " 'optim',\n",
       " 'problem',\n",
       " 'central',\n",
       " 'fashion',\n",
       " 'cellular',\n",
       " 'network',\n",
       " 'model',\n",
       " 'base',\n",
       " 'station',\n",
       " 'usual',\n",
       " 'assum',\n",
       " 'form',\n",
       " 'lattic',\n",
       " 'poisson',\n",
       " 'point',\n",
       " 'process',\n",
       " 'realiti',\n",
       " 'deploy',\n",
       " 'fulli',\n",
       " 'regular',\n",
       " 'complet',\n",
       " 'random',\n",
       " 'accord',\n",
       " 'paper',\n",
       " 'consid',\n",
       " 'general',\n",
       " 'class',\n",
       " 'motion',\n",
       " 'invari',\n",
       " 'model',\n",
       " 'analyz',\n",
       " 'behavior',\n",
       " 'outag',\n",
       " 'probabl',\n",
       " 'probabl',\n",
       " 'signal',\n",
       " 'interfer',\n",
       " 'plus',\n",
       " 'nois',\n",
       " 'ratio',\n",
       " 'sinr',\n",
       " 'smaller',\n",
       " 'threshold',\n",
       " 'threshold',\n",
       " 'go',\n",
       " 'zero',\n",
       " 'remark',\n",
       " 'slope',\n",
       " 'outag',\n",
       " 'probabl',\n",
       " 'function',\n",
       " 'threshold',\n",
       " 'essenti',\n",
       " 'motion',\n",
       " 'invari',\n",
       " 'point',\n",
       " 'process',\n",
       " 'slope',\n",
       " 'mere',\n",
       " 'depend',\n",
       " 'fade',\n",
       " 'statist',\n",
       " 'result',\n",
       " 'introduc',\n",
       " 'notion',\n",
       " 'asymptot',\n",
       " 'deploy',\n",
       " 'gain',\n",
       " 'character',\n",
       " 'horizont',\n",
       " 'success',\n",
       " 'probabl',\n",
       " 'point',\n",
       " 'process',\n",
       " 'high',\n",
       " 'reliabl',\n",
       " 'regim',\n",
       " 'success',\n",
       " 'probabl',\n",
       " 'near',\n",
       " 'demonstr',\n",
       " 'use',\n",
       " 'sinr',\n",
       " 'distribut',\n",
       " 'investig',\n",
       " 'outag',\n",
       " 'probabl',\n",
       " 'adg',\n",
       " 'differ',\n",
       " 'point',\n",
       " 'process',\n",
       " 'fade',\n",
       " 'statist',\n",
       " 'simul',\n",
       " 'molecular',\n",
       " 'communic',\n",
       " 'network',\n",
       " 'realis',\n",
       " 'communic',\n",
       " 'nanoscal',\n",
       " 'devic',\n",
       " 'molecular',\n",
       " 'communic',\n",
       " 'network',\n",
       " 'transmitt',\n",
       " 'receiv',\n",
       " 'communic',\n",
       " 'signal',\n",
       " 'molecul',\n",
       " 'receiv',\n",
       " 'signal',\n",
       " 'molecul',\n",
       " 'react',\n",
       " 'chain',\n",
       " 'chemic',\n",
       " 'reaction',\n",
       " 'produc',\n",
       " 'output',\n",
       " 'molecul',\n",
       " 'count',\n",
       " 'output',\n",
       " 'molecul',\n",
       " 'time',\n",
       " 'output',\n",
       " 'signal',\n",
       " 'receiv',\n",
       " 'output',\n",
       " 'signal',\n",
       " 'noisi',\n",
       " 'stochast',\n",
       " 'natur',\n",
       " 'diffus',\n",
       " 'chemic',\n",
       " 'reaction',\n",
       " 'paper',\n",
       " 'aim',\n",
       " 'characteris',\n",
       " 'properti',\n",
       " 'output',\n",
       " 'signal',\n",
       " 'model',\n",
       " 'transmiss',\n",
       " 'medium',\n",
       " 'transmitt',\n",
       " 'receiv',\n",
       " 'order',\n",
       " 'simplifi',\n",
       " 'analysi',\n",
       " 'model',\n",
       " 'transmitt',\n",
       " 'sequenc',\n",
       " 'specifi',\n",
       " 'number',\n",
       " 'molecul',\n",
       " 'emit',\n",
       " 'transmitt',\n",
       " 'time',\n",
       " 'paper',\n",
       " 'consid',\n",
       " 'receiv',\n",
       " 'reaction',\n",
       " 'mechan',\n",
       " 'revers',\n",
       " 'convers',\n",
       " 'linear',\n",
       " 'catalyt',\n",
       " 'approxim',\n",
       " 'respect',\n",
       " 'ligand',\n",
       " 'receptor',\n",
       " 'bind',\n",
       " 'enzymat',\n",
       " 'reaction',\n",
       " 'mechan',\n",
       " 'choos',\n",
       " 'consid',\n",
       " 'transmitt',\n",
       " 'diffus',\n",
       " 'ordinari',\n",
       " 'differenti',\n",
       " 'equat',\n",
       " 'describ',\n",
       " 'mean',\n",
       " 'behaviour',\n",
       " 'reaction',\n",
       " 'mechan',\n",
       " 'form',\n",
       " 'consid',\n",
       " 'behaviour',\n",
       " 'transmitt',\n",
       " 'signal',\n",
       " 'mean',\n",
       " 'varianc',\n",
       " 'number',\n",
       " 'output',\n",
       " 'molecul',\n",
       " 'receiv',\n",
       " 'reaction',\n",
       " 'mechan',\n",
       " 'differ',\n",
       " 'behaviour',\n",
       " 'deriv',\n",
       " 'analyt',\n",
       " 'express',\n",
       " 'mean',\n",
       " 'varianc',\n",
       " 'frequenc',\n",
       " 'properti',\n",
       " 'number',\n",
       " 'output',\n",
       " 'molecul',\n",
       " 'receiv',\n",
       " 'reaction',\n",
       " 'mechan',\n",
       " 'addit',\n",
       " 'revers',\n",
       " 'convers',\n",
       " 'abl',\n",
       " 'deriv',\n",
       " 'exact',\n",
       " 'probabl',\n",
       " 'distribut',\n",
       " 'number',\n",
       " 'output',\n",
       " 'molecul',\n",
       " 'model',\n",
       " 'allow',\n",
       " 'studi',\n",
       " 'impact',\n",
       " 'design',\n",
       " 'paramet',\n",
       " 'communic',\n",
       " 'perform',\n",
       " 'exampl',\n",
       " 'assum',\n",
       " 'receiv',\n",
       " 'enclos',\n",
       " 'membran',\n",
       " 'studi',\n",
       " 'impact',\n",
       " 'diffus',\n",
       " 'molecul',\n",
       " 'membran',\n",
       " 'communic',\n",
       " 'rformanc',\n",
       " 'paper',\n",
       " 'present',\n",
       " 'statist',\n",
       " 'chatter',\n",
       " 'detect',\n",
       " 'method',\n",
       " 'methodolog',\n",
       " 'base',\n",
       " 'studi',\n",
       " 'discret',\n",
       " 'wavelet',\n",
       " 'transform',\n",
       " 'scheme',\n",
       " 'statist',\n",
       " 'analysi',\n",
       " 'wavelet',\n",
       " 'transform',\n",
       " 'modulus',\n",
       " 'maxima',\n",
       " 'wtmm',\n",
       " 'wavelet',\n",
       " 'transform',\n",
       " 'modulus',\n",
       " 'maxima',\n",
       " 'point',\n",
       " 'wavelet',\n",
       " 'transform',\n",
       " 'signal',\n",
       " 'local',\n",
       " 'maxim',\n",
       " 'correspond',\n",
       " 'time',\n",
       " 'locat',\n",
       " 'noisi',\n",
       " 'machin',\n",
       " 'environ',\n",
       " 'wavelet',\n",
       " 'base',\n",
       " 'nois',\n",
       " 'method',\n",
       " 'includ',\n",
       " 'hybrid',\n",
       " 'threshold',\n",
       " 'function',\n",
       " 'level',\n",
       " 'depend',\n",
       " 'univers',\n",
       " 'threshold',\n",
       " 'rule',\n",
       " 'propos',\n",
       " 'dimension',\n",
       " 'chatter',\n",
       " 'index',\n",
       " 'vari',\n",
       " 'design',\n",
       " 'base',\n",
       " 'statist',\n",
       " 'analysi',\n",
       " 'wtmm',\n",
       " 'main',\n",
       " 'advantag',\n",
       " 'propos',\n",
       " 'chatter',\n",
       " 'index',\n",
       " 'includ',\n",
       " 'variat',\n",
       " 'rang',\n",
       " 'independ',\n",
       " 'process',\n",
       " 'paramet',\n",
       " 'machin',\n",
       " 'system',\n",
       " 'threshold',\n",
       " 'valu',\n",
       " 'suscept',\n",
       " 'cut',\n",
       " 'condit',\n",
       " 'chang',\n",
       " 'valu',\n",
       " 'relat',\n",
       " 'term',\n",
       " 'result',\n",
       " 'chatter',\n",
       " 'index',\n",
       " 'differ',\n",
       " 'machin',\n",
       " 'process',\n",
       " 'time',\n",
       " 'consum',\n",
       " 'recalibr',\n",
       " 'process',\n",
       " 'present',\n",
       " 'multipl',\n",
       " 'person',\n",
       " 'track',\n",
       " 'algorithm',\n",
       " 'base',\n",
       " 'combin',\n",
       " 'particl',\n",
       " 'filter',\n",
       " 'reciproc',\n",
       " 'veloc',\n",
       " 'obstacl',\n",
       " 'agent',\n",
       " 'base',\n",
       " 'crowd',\n",
       " 'model',\n",
       " 'infer',\n",
       " 'collis',\n",
       " 'free',\n",
       " 'veloc',\n",
       " 'predict',\n",
       " 'pedestrian',\n",
       " 'motion',\n",
       " 'addit',\n",
       " 'posit',\n",
       " 'veloc',\n",
       " 'track',\n",
       " 'algorithm',\n",
       " 'estim',\n",
       " 'intern',\n",
       " 'goal',\n",
       " 'desir',\n",
       " 'destin',\n",
       " 'desir',\n",
       " 'veloc',\n",
       " 'track',\n",
       " 'pedestrian',\n",
       " 'onlin',\n",
       " 'manner',\n",
       " 'remov',\n",
       " 'need',\n",
       " 'specifi',\n",
       " 'inform',\n",
       " 'furthermor',\n",
       " 'leverag',\n",
       " 'longer',\n",
       " 'term',\n",
       " 'predict',\n",
       " 'deriv',\n",
       " 'higher',\n",
       " 'order',\n",
       " 'aggreg',\n",
       " 'multipl',\n",
       " 'predict',\n",
       " 'differ',\n",
       " 'prior',\n",
       " 'time',\n",
       " 'step',\n",
       " 'yield',\n",
       " 'tracker',\n",
       " 'recov',\n",
       " 'short',\n",
       " 'term',\n",
       " 'occlus',\n",
       " 'spurious',\n",
       " 'nois',\n",
       " 'appear',\n",
       " 'model',\n",
       " 'experiment',\n",
       " 'result',\n",
       " 'track',\n",
       " 'algorithm',\n",
       " 'suitabl',\n",
       " 'predict',\n",
       " 'pedestrian',\n",
       " 'behavior',\n",
       " 'onlin',\n",
       " 'need',\n",
       " 'scene',\n",
       " 'prior',\n",
       " 'hand',\n",
       " 'annot',\n",
       " 'goal',\n",
       " 'inform',\n",
       " 'improv',\n",
       " 'track',\n",
       " 'real',\n",
       " 'world',\n",
       " 'crowd',\n",
       " 'scene',\n",
       " 'frame',\n",
       " 'rat',\n",
       " 'extract',\n",
       " 'latent',\n",
       " 'dimension',\n",
       " 'structur',\n",
       " 'high',\n",
       " 'dimension',\n",
       " 'data',\n",
       " 'paramount',\n",
       " 'import',\n",
       " 'time',\n",
       " 'infer',\n",
       " 'task',\n",
       " 'encount',\n",
       " 'data',\n",
       " 'analyt',\n",
       " 'increas',\n",
       " 'noisi',\n",
       " 'heterogen',\n",
       " 'incomplet',\n",
       " 'dataset',\n",
       " 'need',\n",
       " 'real',\n",
       " 'time',\n",
       " 'process',\n",
       " 'stream',\n",
       " 'data',\n",
       " 'pose',\n",
       " 'major',\n",
       " 'challeng',\n",
       " 'context',\n",
       " 'present',\n",
       " 'paper',\n",
       " 'permeat',\n",
       " 'benefit',\n",
       " 'rank',\n",
       " 'minim',\n",
       " 'scalabl',\n",
       " 'imput',\n",
       " 'miss',\n",
       " 'data',\n",
       " 'track',\n",
       " 'dimension',\n",
       " 'subspac',\n",
       " 'unravel',\n",
       " 'latent',\n",
       " 'possibl',\n",
       " 'multi',\n",
       " 'structur',\n",
       " 'incomplet',\n",
       " 'stream',\n",
       " 'data',\n",
       " 'rank',\n",
       " 'matrix',\n",
       " 'data',\n",
       " 'subspac',\n",
       " 'estim',\n",
       " 'propos',\n",
       " ...]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_subject[11] #words processed in Economics, Econometrics and Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_sub = gensim.corpora.Dictionary(processed_subject) \n",
    "dictionary_sub.filter_extremes(no_below=15, no_above=0.5)\n",
    "# limit? \n",
    "bow_corpus_sub = [dictionary_sub.doc2bow(doc) for doc in processed_subject]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.5951128602027893\t \n",
      "Topic: 0.004*\"surfac\" + 0.004*\"structur\" + 0.004*\"electron\" + 0.003*\"materi\" + 0.003*\"film\" + 0.003*\"method\" + 0.003*\"energi\" + 0.003*\"layer\" + 0.003*\"suicid\" + 0.003*\"graphen\"\n",
      "\n",
      "Score: 0.38198068737983704\t \n",
      "Topic: 0.004*\"cognit\" + 0.004*\"task\" + 0.004*\"research\" + 0.003*\"particip\" + 0.003*\"memori\" + 0.003*\"learn\" + 0.003*\"train\" + 0.003*\"placebo\" + 0.003*\"social\" + 0.003*\"health\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[11]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.10000000149011612\t \n",
      "Topic: 0.011*\"increas\" + 0.009*\"concentr\" + 0.009*\"effect\" + 0.008*\"plant\" + 0.008*\"level\" + 0.008*\"differ\" + 0.007*\"product\" + 0.007*\"signific\" + 0.007*\"diet\" + 0.007*\"speci\"\n",
      "\n",
      "Score: 0.10000000149011612\t \n",
      "Topic: 0.040*\"cell\" + 0.019*\"express\" + 0.014*\"activ\" + 0.011*\"induc\" + 0.010*\"effect\" + 0.008*\"level\" + 0.008*\"increas\" + 0.008*\"cancer\" + 0.008*\"regul\" + 0.008*\"protein\"\n",
      "\n",
      "Score: 0.10000000149011612\t \n",
      "Topic: 0.024*\"protein\" + 0.014*\"activ\" + 0.011*\"bind\" + 0.009*\"structur\" + 0.008*\"acid\" + 0.007*\"compound\" + 0.007*\"interact\" + 0.007*\"complex\" + 0.006*\"membran\" + 0.006*\"function\"\n",
      "\n",
      "Score: 0.10000000149011612\t \n",
      "Topic: 0.015*\"health\" + 0.008*\"particip\" + 0.008*\"children\" + 0.007*\"care\" + 0.007*\"research\" + 0.006*\"effect\" + 0.006*\"intervent\" + 0.006*\"relat\" + 0.005*\"provid\" + 0.005*\"data\"\n",
      "\n",
      "Score: 0.10000000149011612\t \n",
      "Topic: 0.015*\"model\" + 0.012*\"method\" + 0.011*\"imag\" + 0.009*\"base\" + 0.009*\"data\" + 0.007*\"propos\" + 0.007*\"result\" + 0.007*\"perform\" + 0.006*\"approach\" + 0.006*\"measur\"\n",
      "\n",
      "Score: 0.10000000149011612\t \n",
      "Topic: 0.008*\"surfac\" + 0.008*\"high\" + 0.007*\"properti\" + 0.007*\"extract\" + 0.006*\"result\" + 0.006*\"effect\" + 0.006*\"materi\" + 0.006*\"method\" + 0.005*\"temperatur\" + 0.005*\"structur\"\n",
      "\n",
      "Score: 0.10000000149011612\t \n",
      "Topic: 0.012*\"pain\" + 0.012*\"measur\" + 0.010*\"time\" + 0.009*\"signific\" + 0.008*\"pressur\" + 0.008*\"blood\" + 0.008*\"perform\" + 0.008*\"differ\" + 0.008*\"arteri\" + 0.008*\"mean\"\n",
      "\n",
      "Score: 0.10000000149011612\t \n",
      "Topic: 0.010*\"group\" + 0.010*\"brain\" + 0.007*\"muscl\" + 0.007*\"control\" + 0.007*\"function\" + 0.006*\"signific\" + 0.006*\"neuron\" + 0.006*\"bone\" + 0.006*\"differ\" + 0.006*\"increas\"\n",
      "\n",
      "Score: 0.10000000149011612\t \n",
      "Topic: 0.044*\"patient\" + 0.013*\"group\" + 0.012*\"associ\" + 0.011*\"risk\" + 0.011*\"year\" + 0.010*\"treatment\" + 0.010*\"clinic\" + 0.009*\"signific\" + 0.009*\"diseas\" + 0.007*\"outcom\"\n",
      "\n",
      "Score: 0.10000000149011612\t \n",
      "Topic: 0.023*\"gene\" + 0.009*\"genet\" + 0.009*\"sequenc\" + 0.009*\"speci\" + 0.009*\"identifi\" + 0.009*\"genom\" + 0.007*\"mutat\" + 0.007*\"analysi\" + 0.006*\"isol\" + 0.006*\"develop\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus_sub[11]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
