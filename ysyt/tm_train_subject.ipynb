{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataframe that matches paper abstract with subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_id = []\n",
    "abstract = []\n",
    "\n",
    "f = open('aminer_2014.txt','r',encoding = 'utf8')\n",
    "f.readline()\n",
    "for i, line in enumerate(f):\n",
    "        if (i+2) % 250000 == 0:\n",
    "            print('file '+file+': ',round((i+2)/1000000*100,1),\"%\")\n",
    "        json_line = json.loads(line)\n",
    "        if 'year' in json_line and 'keywords' in json_line and \\\n",
    "        'abstract' in json_line and 'lang' in json_line and \\\n",
    "        'references' in json_line and 'issn' in json_line:\n",
    "            \n",
    "            if json_line['lang'] == 'en' :\n",
    "                \n",
    "                ## store paper info, later use to get the subject of the paper\n",
    "                paper_id.append(json_line['id'])\n",
    "                abstract.append(json_line['abstract'])\n",
    "\n",
    "                \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53e997a2b7602d9701f74cf7</th>\n",
       "      <td>The nursing care of a patient following subara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e997a6b7602d9701f7c67f</th>\n",
       "      <td>The authors wish to thank G. W. Beakley and F....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e997aab7602d9701f827a4</th>\n",
       "      <td>\\n Almost all problems known to theoretical ec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e997aeb7602d9701f8af9c</th>\n",
       "      <td>Pain management in emergency departments (EDs)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e997b5b7602d9701f97a9d</th>\n",
       "      <td>Provides an abstract for each of the two keyno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e997bab7602d9701fa1ddc</th>\n",
       "      <td>Howard drifted back into consciousness. For a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e997bab7602d9701fa3207</th>\n",
       "      <td>Last week, Nature painted a pessimistic pictur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e997c6b7602d9701fb6228</th>\n",
       "      <td>In the first article in the series on risk man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e997c6b7602d9701fb7afb</th>\n",
       "      <td>This introduction to the special section on Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e997c6b7602d9701fb8e1b</th>\n",
       "      <td>The notion of a “negative-result” measurement ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e997ccb7602d9701fbe973</th>\n",
       "      <td>Understanding and ameliorating the effects of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e997e4b7602d9701fdb233</th>\n",
       "      <td>Most work on the topic of activity landscapes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e997ecb7602d9701fe84a0</th>\n",
       "      <td>This paper aims first at a simultaneous axioma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e997f1b7602d9701ff3a22</th>\n",
       "      <td>First Page of the Article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e997f1b7602d9701ff3a32</th>\n",
       "      <td>Professor Koren's comments on my paper raise a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e997f1b7602d9701ff3a35</th>\n",
       "      <td>First Page of the Article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e997f5b7602d9701ffb728</th>\n",
       "      <td>We develop novel single-GPU parallelisations o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99800b7602d970201041b</th>\n",
       "      <td>The spectrum of human pathogens and the infect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99803b7602d970201376c</th>\n",
       "      <td>You know wireless technology has arrived when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99808b7602d970201aac7</th>\n",
       "      <td>We consider the setting where actions can be u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9980eb7602d970202737c</th>\n",
       "      <td>Erdheim-Chester disease is an orphan condition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9981db7602d9702038d28</th>\n",
       "      <td>We describe a novel concept, situation awarene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9981db7602d970203af7a</th>\n",
       "      <td>Spontaneous intracranial hypotension (SIH) is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9981db7602d970203b380</th>\n",
       "      <td>Socially-based recommendation systems have rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9981db7602d970203c14a</th>\n",
       "      <td>Superpixels provide an over-segmentation repre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9982cb7602d97020536e3</th>\n",
       "      <td>Progress in pediatric palliative care has gain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99832b7602d9702055264</th>\n",
       "      <td>Present platelet storage media often designate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99832b7602d97020557fa</th>\n",
       "      <td>Emergency department (ED) attendances are, by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99833b7602d9702058230</th>\n",
       "      <td>In this paper, a novel Genetic Generalized Dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99833b7602d970205b13f</th>\n",
       "      <td>Chemotherapy-induced nausea and vomiting (CINV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99fbcb7602d9702893f24</th>\n",
       "      <td>The demand for novel molecularly targeted drug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99fd7b7602d97028b6342</th>\n",
       "      <td>Notions of core, support, and inversion of a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99fddb7602d97028b750e</th>\n",
       "      <td>In this study, a novel phase offset-based part...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99fddb7602d97028baf31</th>\n",
       "      <td>In this paper, we propose a novel image scalin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99fe4b7602d97028c2c67</th>\n",
       "      <td>The diverse set of human brain structure and f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99fe4b7602d97028c2fcd</th>\n",
       "      <td>Biomedical prediction based on clinical and ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99fe9b7602d97028c74bf</th>\n",
       "      <td>The ever increasing volume of referrals from p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99fe9b7602d97028c9bda</th>\n",
       "      <td>FINDbase (http://www.findbase.org) aims to doc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99ff0b7602d97028cdd28</th>\n",
       "      <td>Metagenomics is a relatively recently establis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99ff5b7602d97028da82b</th>\n",
       "      <td>Ventromedial prefrontal cortex (vmPFC) forms a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99ffcb7602d97028e0449</th>\n",
       "      <td>The splitting approach is developed for the nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9a002b7602d97028e4ee9</th>\n",
       "      <td>The Human microRNA Disease Database (HMDD; ava...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9a00ab7602d97028ef703</th>\n",
       "      <td>Organizations today regularly share their cust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9a011b7602d97028f603f</th>\n",
       "      <td>Batch processing happens in many different ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9a018b7602d97028f898c</th>\n",
       "      <td>As the most popular video sharing website in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9a026b7602d970290758f</th>\n",
       "      <td>Cardiovascular disease remains the leading cau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9a02cb7602d970290f5a3</th>\n",
       "      <td>Estimating the behavior of a network of neuron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9a02db7602d97029119d1</th>\n",
       "      <td>As part of our research on programmed self-dec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9a034b7602d9702919206</th>\n",
       "      <td>The automatic identification of epileptic EEG ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9a034b7602d9702919bc0</th>\n",
       "      <td>The objectives of this Perspective paper are t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9a034b7602d970291b7bf</th>\n",
       "      <td>Phylogenetics and population genetics are cent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9a03bb7602d970291df55</th>\n",
       "      <td>Single Nucleotide Polymorphism (SNP) genotypin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9a03bb7602d970292413f</th>\n",
       "      <td>Link adaptation using adaptive modulation and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9a049b7602d970292f58f</th>\n",
       "      <td>Code interoperability and the search for domai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9a04ab7602d970292fd1b</th>\n",
       "      <td>The purpose of protection circuits in ultrasou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9a04ab7602d9702930d5b</th>\n",
       "      <td>The BloodChIP database (http://www.med.unsw.ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9a04ab7602d9702932d83</th>\n",
       "      <td>Prediction of the structural classes of protei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9a051b7602d9702936b9f</th>\n",
       "      <td>Mathematical modeling is often used to formali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9a06db7602d9702956f3f</th>\n",
       "      <td>DNA methylation undergoes dynamic changes duri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9a07ab7602d9702963d30</th>\n",
       "      <td>Empathy involves experiencing emotion vicariou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234253 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   abstract\n",
       "id                                                                         \n",
       "53e997a2b7602d9701f74cf7  The nursing care of a patient following subara...\n",
       "53e997a6b7602d9701f7c67f  The authors wish to thank G. W. Beakley and F....\n",
       "53e997aab7602d9701f827a4  \\n Almost all problems known to theoretical ec...\n",
       "53e997aeb7602d9701f8af9c  Pain management in emergency departments (EDs)...\n",
       "53e997b5b7602d9701f97a9d  Provides an abstract for each of the two keyno...\n",
       "53e997bab7602d9701fa1ddc  Howard drifted back into consciousness. For a ...\n",
       "53e997bab7602d9701fa3207  Last week, Nature painted a pessimistic pictur...\n",
       "53e997c6b7602d9701fb6228  In the first article in the series on risk man...\n",
       "53e997c6b7602d9701fb7afb  This introduction to the special section on Re...\n",
       "53e997c6b7602d9701fb8e1b  The notion of a “negative-result” measurement ...\n",
       "53e997ccb7602d9701fbe973  Understanding and ameliorating the effects of ...\n",
       "53e997e4b7602d9701fdb233  Most work on the topic of activity landscapes ...\n",
       "53e997ecb7602d9701fe84a0  This paper aims first at a simultaneous axioma...\n",
       "53e997f1b7602d9701ff3a22                          First Page of the Article\n",
       "53e997f1b7602d9701ff3a32  Professor Koren's comments on my paper raise a...\n",
       "53e997f1b7602d9701ff3a35                          First Page of the Article\n",
       "53e997f5b7602d9701ffb728  We develop novel single-GPU parallelisations o...\n",
       "53e99800b7602d970201041b  The spectrum of human pathogens and the infect...\n",
       "53e99803b7602d970201376c  You know wireless technology has arrived when ...\n",
       "53e99808b7602d970201aac7  We consider the setting where actions can be u...\n",
       "53e9980eb7602d970202737c  Erdheim-Chester disease is an orphan condition...\n",
       "53e9981db7602d9702038d28  We describe a novel concept, situation awarene...\n",
       "53e9981db7602d970203af7a  Spontaneous intracranial hypotension (SIH) is ...\n",
       "53e9981db7602d970203b380  Socially-based recommendation systems have rec...\n",
       "53e9981db7602d970203c14a  Superpixels provide an over-segmentation repre...\n",
       "53e9982cb7602d97020536e3  Progress in pediatric palliative care has gain...\n",
       "53e99832b7602d9702055264  Present platelet storage media often designate...\n",
       "53e99832b7602d97020557fa  Emergency department (ED) attendances are, by ...\n",
       "53e99833b7602d9702058230  In this paper, a novel Genetic Generalized Dis...\n",
       "53e99833b7602d970205b13f  Chemotherapy-induced nausea and vomiting (CINV...\n",
       "...                                                                     ...\n",
       "53e99fbcb7602d9702893f24  The demand for novel molecularly targeted drug...\n",
       "53e99fd7b7602d97028b6342  Notions of core, support, and inversion of a s...\n",
       "53e99fddb7602d97028b750e  In this study, a novel phase offset-based part...\n",
       "53e99fddb7602d97028baf31  In this paper, we propose a novel image scalin...\n",
       "53e99fe4b7602d97028c2c67  The diverse set of human brain structure and f...\n",
       "53e99fe4b7602d97028c2fcd  Biomedical prediction based on clinical and ge...\n",
       "53e99fe9b7602d97028c74bf  The ever increasing volume of referrals from p...\n",
       "53e99fe9b7602d97028c9bda  FINDbase (http://www.findbase.org) aims to doc...\n",
       "53e99ff0b7602d97028cdd28  Metagenomics is a relatively recently establis...\n",
       "53e99ff5b7602d97028da82b  Ventromedial prefrontal cortex (vmPFC) forms a...\n",
       "53e99ffcb7602d97028e0449  The splitting approach is developed for the nu...\n",
       "53e9a002b7602d97028e4ee9  The Human microRNA Disease Database (HMDD; ava...\n",
       "53e9a00ab7602d97028ef703  Organizations today regularly share their cust...\n",
       "53e9a011b7602d97028f603f  Batch processing happens in many different ind...\n",
       "53e9a018b7602d97028f898c  As the most popular video sharing website in t...\n",
       "53e9a026b7602d970290758f  Cardiovascular disease remains the leading cau...\n",
       "53e9a02cb7602d970290f5a3  Estimating the behavior of a network of neuron...\n",
       "53e9a02db7602d97029119d1  As part of our research on programmed self-dec...\n",
       "53e9a034b7602d9702919206  The automatic identification of epileptic EEG ...\n",
       "53e9a034b7602d9702919bc0  The objectives of this Perspective paper are t...\n",
       "53e9a034b7602d970291b7bf  Phylogenetics and population genetics are cent...\n",
       "53e9a03bb7602d970291df55  Single Nucleotide Polymorphism (SNP) genotypin...\n",
       "53e9a03bb7602d970292413f  Link adaptation using adaptive modulation and ...\n",
       "53e9a049b7602d970292f58f  Code interoperability and the search for domai...\n",
       "53e9a04ab7602d970292fd1b  The purpose of protection circuits in ultrasou...\n",
       "53e9a04ab7602d9702930d5b  The BloodChIP database (http://www.med.unsw.ed...\n",
       "53e9a04ab7602d9702932d83  Prediction of the structural classes of protei...\n",
       "53e9a051b7602d9702936b9f  Mathematical modeling is often used to formali...\n",
       "53e9a06db7602d9702956f3f  DNA methylation undergoes dynamic changes duri...\n",
       "53e9a07ab7602d9702963d30  Empathy involves experiencing emotion vicariou...\n",
       "\n",
       "[234253 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.DataFrame()\n",
    "df['id'] = paper_id\n",
    "df['abstract'] = abstract\n",
    "df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53e997a2b7602d9701f74cf7</td>\n",
       "      <td>The nursing care of a patient following subara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53e997a6b7602d9701f7c67f</td>\n",
       "      <td>The authors wish to thank G. W. Beakley and F....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53e997aab7602d9701f827a4</td>\n",
       "      <td>\\n Almost all problems known to theoretical ec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53e997aeb7602d9701f8af9c</td>\n",
       "      <td>Pain management in emergency departments (EDs)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53e997b5b7602d9701f97a9d</td>\n",
       "      <td>Provides an abstract for each of the two keyno...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                                           abstract\n",
       "0  53e997a2b7602d9701f74cf7  The nursing care of a patient following subara...\n",
       "1  53e997a6b7602d9701f7c67f  The authors wish to thank G. W. Beakley and F....\n",
       "2  53e997aab7602d9701f827a4  \\n Almost all problems known to theoretical ec...\n",
       "3  53e997aeb7602d9701f8af9c  Pain management in emergency departments (EDs)...\n",
       "4  53e997b5b7602d9701f97a9d  Provides an abstract for each of the two keyno..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = pd.read_csv('paper_subject_match.csv',index_col = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_subject</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53e99784b7602d9701f3e13e</th>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99784b7602d9701f3e4f2</th>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e9978db7602d9701f4f415</th>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99792b7602d9701f56a86</th>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53e99792b7602d9701f5b087</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          paper_subject\n",
       "id                                     \n",
       "53e99784b7602d9701f3e13e           13.0\n",
       "53e99784b7602d9701f3e4f2           13.0\n",
       "53e9978db7602d9701f4f415           13.0\n",
       "53e99792b7602d9701f56a86           27.0\n",
       "53e99792b7602d9701f5b087            NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = pd.merge(df, subject, on = ['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "abstract             0\n",
       "paper_subject    12413\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234253"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = tm.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = tm.drop(columns = ['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm['paper_subject'] = tm['paper_subject'].apply(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tm.paper_subject.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n Almost all problems known to theoretical ec...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pain management in emergency departments (EDs)...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Provides an abstract for each of the two keyno...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Howard drifted back into consciousness. For a ...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Last week, Nature painted a pessimistic pictur...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract  paper_subject\n",
       "2  \\n Almost all problems known to theoretical ec...             33\n",
       "3  Pain management in emergency departments (EDs)...             29\n",
       "4  Provides an abstract for each of the two keyno...             27\n",
       "5  Howard drifted back into consciousness. For a ...             31\n",
       "6  Last week, Nature painted a pessimistic pictur...             10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Topic models for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bysub = list()\n",
    "for x in range(10,37):\n",
    "    bysub.append(tm[tm['paper_subject'] == x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Processing the abstract:**\n",
    "- Tokenization: Split the text into sentences and the sentences into words. Lowercase the words and remove punctuation\n",
    "- Words that have fewer than 3 characters are removed\n",
    "- All stopwords are removed\n",
    "- lemmatized — words in third person to first person, verbs in past and future tenses to present\n",
    "- Stemmed — words are reduced to their root form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install gensim\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/yihuan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v')) #lemmatize as verb, default is noun\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['One', 'of', 'the', 'most', 'important', 'challenges', 'in', 'network', 'science', 'is', 'to', 'quantify', 'the', 'information', 'encoded', 'in', 'complex', 'network', 'structures.', 'Disentangling', 'randomness', 'from', 'organizational', 'principles', 'is', 'even', 'more', 'demanding', 'when', 'networks', 'have', 'a', 'multiplex', 'nature.', 'Multiplex', 'networks', 'are', 'multilayer', 'systems', 'of', '[Formula:', 'see', 'text]', 'nodes', 'that', 'can', 'be', 'linked', 'in', 'multiple']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['import', 'challeng', 'network', 'scienc', 'quantifi', 'inform', 'encod', 'complex', 'network', 'structur', 'disentangl', 'random', 'organiz', 'principl', 'demand', 'network', 'multiplex', 'natur', 'multiplex', 'network', 'multilay', 'system', 'formula']\n"
     ]
    }
   ],
   "source": [
    "#example of processed document\n",
    "stemmer = SnowballStemmer('english') #Create a new instance of a language specific subclass\n",
    "doc_sample = bysub[1].values[0][0]\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words[:50])\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample[:300]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = list()\n",
    "for i in range(len(bysub)):\n",
    "    processed_docs.append(bysub[i]['abstract'].map(preprocess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs[2].values[0] #words processed in first abstract of Arts and Humanities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for Running LDA using TF-IDF\n",
    "#i is subject index, text_str is sentence/abstract\n",
    "from gensim import corpora, models\n",
    "def LDA_TF_sub(i,text_str = \"\"):\n",
    "    dictionary_i = gensim.corpora.Dictionary(processed_docs[i]) \n",
    "    bow_corpus_i = [dictionary_i.doc2bow(doc) for doc in processed_docs[i]]\n",
    "    tfidf_i = models.TfidfModel(bow_corpus_i)\n",
    "    corpus_tfidf_i = tfidf_i[bow_corpus_i]\n",
    "    lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf_i, num_topics=10, id2word=dictionary_i, passes=2, workers=4)\n",
    "    if len(text_str) != 0:\n",
    "        bow_vector = dictionary_i.doc2bow(preprocess(text_str))\n",
    "        for index, score in sorted(lda_model_tfidf[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "            print(\"\\nScore: {}\\n Topic: {}\".format(score, lda_model_tfidf.print_topic(index, 5)))\n",
    "    return(lda_model_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample models in Arts and Humanities:\n",
    "for idx, topic in LDA_TF_sub(2).print_topics(-1):\n",
    "        print('Topic: {} Word: {}'.format(idx, topic))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample article in art and see how good is the result\n",
    "sub2abs = np.array2string(bysub[2].values[595])\n",
    "LDA_TF_sub(2,text_str = sub2abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array2string(bysub[2].values[595])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample 100 papers in arts and feed into each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = []\n",
    "for i in range(len(processed_docs)):\n",
    "    dictionary.append(gensim.corpora.Dictionary(processed_docs[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "def LDA_TF_sub_models(i,text_str = \"\"):\n",
    "    dictionary[i] = gensim.corpora.Dictionary(processed_docs[i]) \n",
    "    bow_corpus_i = [dictionary[i].doc2bow(doc) for doc in processed_docs[i]]\n",
    "    tfidf_i = models.TfidfModel(bow_corpus_i)\n",
    "    corpus_tfidf_i = tfidf_i[bow_corpus_i]\n",
    "    lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf_i, num_topics=10, id2word=dictionary[i], passes=2, workers=4)\n",
    "    return(lda_model_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_TF_sub_models(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allmodels = []\n",
    "for i in range(27):\n",
    "    allmodels.append(LDA_TF_sub_models(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, topic in allmodels[2].print_topics(-1):\n",
    "        print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_models(i, text_str):\n",
    "        bow_vector = dictionary[i].doc2bow(preprocess(text_str))\n",
    "        score = sorted(allmodels[i][bow_vector], key=lambda tup: -1*tup[1])[0]\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_models(2,sub2abs)[1] #the score of sample article in art, for the art model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_models(8,sub2abs)[1] #the score of sample article in art, for the computer science model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = bysub[2]['abstract'].sample(n=200, random_state=1) #sample of 200 subjects from art and humanities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the sample abstract have a highest topic score > 0.6, then count it in the result\n",
    "result = {}\n",
    "for x in range(27):\n",
    "    highscore = 0\n",
    "    for i,val in enumerate(sample):\n",
    "        if feed_models(x,text_str = val)[1] > 0.6:\n",
    "            highscore += 1\n",
    "    result.update({x: highscore})\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(result.items()), columns = [\"subject\", \"high score count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.title(\"count for 200 sampes from Humanity/Art topics\")\n",
    "ax = sns.barplot(x=\"subject\", y=\"high score count\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "n = 100\n",
    "for i in range(n):\n",
    "    sample = bysub[2]['abstract'].sample(n=200, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't run, only used if you want highest score returned for every string\n",
    "from gensim import corpora, models\n",
    "def LDA_TF_sub_easy(i,text_str = \"\"):\n",
    "    bow_corpus_i = [dictionary[i].doc2bow(doc) for doc in processed_docs[i]]\n",
    "    tfidf_i = models.TfidfModel(bow_corpus_i)\n",
    "    corpus_tfidf_i = tfidf_i[bow_corpus_i]\n",
    "    lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf_i, num_topics=10, id2word=dictionary[i], passes=2, workers=4)\n",
    "    if len(text_str) != 0:\n",
    "        bow_vector = dictionary[i].doc2bow(preprocess(text_str))\n",
    "        score = sorted(lda_model_tfidf[bow_vector], key=lambda tup: -1*tup[1])[0]\n",
    "    return(score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't run. Only used if you want to store the topic scores and words\n",
    "from gensim import corpora, models\n",
    "def LDA_TF_sub_store(i,text_str = \"\"):\n",
    "    bow_corpus_i = [dictionary[i].doc2bow(doc) for doc in processed_docs[i]]\n",
    "    tfidf_i = models.TfidfModel(bow_corpus_i)\n",
    "    corpus_tfidf_i = tfidf_i[bow_corpus_i]\n",
    "    lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf_i, num_topics=10, id2word=dictionary[i], passes=2, workers=4)\n",
    "    topic_score = []\n",
    "    topic_perc = []\n",
    "    if len(text_str) != 0:\n",
    "        bow_vector = dictionary[i].doc2bow(preprocess(text_str))\n",
    "        for index, score in sorted(lda_model_tfidf[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "            topic_score.append(score)\n",
    "            topic_perc.append(lda_model_tfidf.show_topics(formatted = False)[i][1])\n",
    "    result = list([topic_score, topic_perc])\n",
    "    return(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
